{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb87a",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "These handle importing necessary libraries, preparation of the feature arrays for Machine Learning, and execution of Machine Learning training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f008279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from Scripts_Python.ML_Python_Build_FeatureArrays_FromROOT import Build_FeatureArrays_FromROOT\n",
    "from Scripts_Python.ML_Python_TrainTest import (\n",
    "    Build_FeatureArrays_FromCSV,\n",
    "    Write_MLResults_ToCSV,\n",
    "    Write_MLCoefficients_ToCSV,\n",
    "    Train_All_Estimators,\n",
    "    Train_LinearRegression,\n",
    "    Train_RandomForestRegression,\n",
    "    Train_MLPRegression,\n",
    "    Test_Estimator,\n",
    "    Test_All_Estimators,\n",
    "    Full_TrainTest)\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#                                         #\n",
    "#     DATA PREPARATION - CHANGE BELOW     #\n",
    "#                                         #\n",
    "###########################################\n",
    "\n",
    "# File Directories\n",
    "file_directory   = \"../../Files/Test/\"\n",
    "output_directory = file_directory\n",
    "csv_directory    = file_directory + \"CSV_Backup/\"\n",
    "\n",
    "# Training Data Sources\n",
    "train_file_prep_arr = [  \n",
    "    # String tuple with: \n",
    "    # (0:\"File_Name.root\",   1:\"Tree_Name\",\n",
    "    #  2:\"Base_Name\",   3:\"Bias\",   4:(pt_min, pt_max))\n",
    "    (\"Full_Train_B8_10_90_N500000_ML_Prep.root\", \"ML_Train_B8_10_90_N500000_Flat\",\n",
    "     \"Train_B8_Flat_10_90\", \"B8_Flat\", (10., 90.)),\n",
    "#     (\"Full_Train_B8_10_90_N500000_ML_Prep.root\", \"ML_Train_B8_10_90_N500000\",\n",
    "#      \"Train_B8_10_90\",      \"B8\",   (10., 90.)),\n",
    "#     (\"Full_Train_B4_10_90_N500000_ML_Prep.root\", \"ML_Train_B4_10_90_N500000\",\n",
    "#      \"Train_B4_10_90\",      \"B4\",   (10., 90.)),\n",
    "#     (\"Full_Train_B0_10_90_N500000_ML_Prep.root\", \"ML_Train_B0_10_90_N500000\",\n",
    "#      \"Train_B8_10_90\",      \"B0\",   (10., 90.))\n",
    "]\n",
    "\n",
    "# Testing Data Sources\n",
    "test_file_prep_arr = [\n",
    "    # String tuple with: \n",
    "    # (0:\"File_Name.root\",   1:\"Tree_Name\",\n",
    "    #  2:\"Base_Name\",   3:\"Bias\",   4:(pt_min, pt_max))\n",
    "    (\"Full_Test_B8_10_90_N500000_ML_Prep.root\", \"ML_Test_B8_10_90_N500000_Flat\", \n",
    "     \"Test_Flat_10_90\", \"B8_Flat\", (10., 90.))\n",
    "]\n",
    "\n",
    "# Testing pT Bins\n",
    "test_bin_array = [\n",
    "    # Tuple with:\n",
    "    # (0:\"Test Label / Folder Name\", \n",
    "    #  1:(Training bins: (min,max), (min,max),...), 3:Optional testing bin (min,max))\n",
    "#     (\"Test_4GeV_Bins\", \n",
    "#      ((18,22), (28,32), (38,42), (48,52), (58,62), (68,72), (78,82))),\n",
    "#     (\"Test_Centered_Wide_Bins\", \n",
    "#      ((40,60), (30,70), (20,80), (10,90)))\n",
    "    (\"Train_Centered_Test_40_60\", \n",
    "     ((40,60), (30,70), (20,80), (10,90)), (40,60)) # <- Includes a 3rd index item\n",
    "]\n",
    "\n",
    "# Training and Testing pT Bins\n",
    "traintest_bin_array = [ \n",
    "    # Tuple with:\n",
    "    # (0:\"Test Label / Folder Name\", \n",
    "    #  1:(Training bins: (min,max), (min,max),...), 3:Optional testing bin (min,max))\n",
    "#     (\"Train_20GeV_Bins\", \n",
    "#      ((10,30), (20,40), (30,50), (40,60), (50,70), (60,80), (70,90))),\n",
    "#     (\"Train_30GeV_Bins\", \n",
    "#      ((10,40), (20,50), (30,60), (40,70), (50,80), (60,90))),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "########## ANYTHING BELOW THIS SHOULDN'T NEED TO CHANGE ##########\n",
    "\n",
    "\n",
    "\n",
    "# Builds output directories\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "    print(\"made output directory\")\n",
    "except:\n",
    "    print(\"Output directory already exists or not made\")\n",
    "    \n",
    "try:\n",
    "    os.mkdir(csv_directory)\n",
    "    print(\"made 'CSV_Backup' directory\")\n",
    "except:\n",
    "    print(\"'CSV_Backup/' already exists or not made\")\n",
    "\n",
    "# Builds feature and target arrays from root file, or skips them if csv already exists\n",
    "\n",
    "# Training data\n",
    "train_file_bundle = []\n",
    "for train_file_info in train_file_prep_arr:\n",
    "    train_file_path  = file_directory + train_file_info[0]\n",
    "    train_csv_path   = csv_directory + \"ML_CSV_\" + train_file_info[2] + \".csv\"\n",
    "    train_file_bundle.append((train_csv_path, train_file_info[2], train_file_info[3]))\n",
    "    if not os.path.exists(train_csv_path):\n",
    "        X_train, y_train, sc_train = Build_FeatureArrays_FromROOT(\n",
    "            train_file_path, train_file_info[1], train_csv_path, train_file_info[4][0], train_file_info[4][1])\n",
    "        \n",
    "# Testing data\n",
    "test_file_bundle = []\n",
    "for test_file_info in test_file_prep_arr:\n",
    "    test_file_path   = file_directory + test_file_info[0]\n",
    "    test_csv_path    = csv_directory + \"ML_CSV_\" + test_file_info[2] + \".csv\"\n",
    "    test_file_bundle.append((test_csv_path, test_file_info[2], test_file_info[3]))\n",
    "    if not os.path.exists(test_csv_path):\n",
    "        X_test, y_test, sc_test = Build_FeatureArrays_FromROOT(\n",
    "            test_file_path,  test_file_info[1],  test_csv_path,  test_file_info[4][0],  test_file_info[4][1])\n",
    "\n",
    "# Set Features to train with\n",
    "# X_values[\n",
    "#    0  jet_pt_raw,      1  jet_pt_corr,     2  jet_mass,        3  jet_area, \n",
    "#    4  jet_area_err,    5  jet_const_n,     6  const_pt_mean,   7  const_pt_median, \n",
    "#    8  const_1_pt,      9  const_2_pt,      10 const_3_pt,      11 const_4_pt,\n",
    "#    12 const_5_pt,      13 const_6_pt,      14 const_7_pt,      15 const_8_pt,\n",
    "#    16 const_9_pt,      17 const_10_pt,     18 jet_y,           19 jet_phi,\n",
    "#    20 jet_rho]\n",
    "\n",
    "# Training with 1 feature\n",
    "feature_label_1feat = [\n",
    "    \"jet_pt_raw\"]\n",
    "feature_index_1feat = [0]\n",
    "\n",
    "# Training with 3 features\n",
    "feature_label_3feat = [\n",
    "    \"jet_pt_raw\", \"jet_area\", \"jet_rho\"]\n",
    "feature_index_3feat = [0, 3, 20]\n",
    "\n",
    "# Training with 11 features (removes jet_pt_corr)\n",
    "feature_label_11feat = [\n",
    "    \"jet_pt_raw\",                      \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_11feat = [0,    2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "# Training with 12 features\n",
    "feature_label_12feat = [\n",
    "    \"jet_pt_raw\",    \"jet_pt_corr\",    \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_12feat = [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "# CONSIDERATIONS:\n",
    "# get rid of jet_pt_corr - why not try to correct without it?\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d3507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_bundle = [\n",
    "    (feature_label_1feat,  feature_index_1feat), \n",
    "    (feature_label_3feat,  feature_index_3feat),\n",
    "    (feature_label_12feat, feature_index_12feat),\n",
    "    (feature_label_11feat, feature_index_11feat)\n",
    "]\n",
    "\n",
    "Full_TrainTest(\n",
    "    train_file_bundle,  # train_file_bundle\n",
    "    test_file_bundle,   # test_file_bundle\n",
    "    feature_bundle,     # feature_bundle\n",
    "    test_bin_array,     # test_bin_array\n",
    "    traintest_bin_array,# traintest_bin_array\n",
    "    output_directory,   # output_directory\n",
    "    10.,       # train_pt_min\n",
    "    90.,       # train_pt_max\n",
    "    use_lr  = True,     # use_lr\n",
    "    use_rf  = True,     # use_rf\n",
    "    use_mlp = True      # use_mlp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
